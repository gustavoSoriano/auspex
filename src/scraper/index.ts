import { validateUrl } from "../security/url-validator.js";
import { Tier1HTTP } from "./tiers/tier1-http.js";
import { Tier2Stealth } from "./tiers/tier2-stealth.js";
import { Tier3Browser } from "./tiers/tier3-browser.js";
import { extractLinksWithMetadata } from "./extractors/content.js";
import type {
  MapLink,
  MapOptions,
  MapResult,
  ScrapeOptions,
  ScrapeResult,
  ScraperConfig,
} from "./types.js";

// â”€â”€â”€ Scraper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
//
// Scraper de alta qualidade com fallback automÃ¡tico em 3 tiers:
//
//   Tier 1 â†’ HTTP puro (got-scraping)         (~100-500ms, sem browser)
//              â†“ bloqueado ou conteÃºdo insuficiente (SPA, anti-bot bÃ¡sico)
//   Tier 2 â†’ HTTP Stealth (got-scraping)      (~200-800ms, TLS fingerprint)
//              â†“ ainda bloqueado ou SPA sem SSR
//   Tier 3 â†’ Playwright Chromium + stealth    (~2-10s, browser completo)
//
// Anti-SSRF integrado: todas as URLs sÃ£o validadas antes do scrape.
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export class Scraper {
  private readonly tier1: Tier1HTTP;
  private readonly tier2: Tier2Stealth;
  private readonly tier3: Tier3Browser;
  private readonly config: {
    timeout: number;
    verbose: boolean;
    forceTier?: ScraperConfig["forceTier"];
    allowedDomains?: string[];
    blockedDomains?: string[];
  };

  constructor(private readonly fullConfig: ScraperConfig = {}) {
    this.tier1 = new Tier1HTTP();
    this.tier2 = new Tier2Stealth();
    this.tier3 = new Tier3Browser(fullConfig.browserConfig);
    this.config = {
      timeout: fullConfig.timeout ?? 30_000,
      verbose: fullConfig.verbose ?? false,
      forceTier: fullConfig.forceTier,
      allowedDomains: fullConfig.allowedDomains,
      blockedDomains: fullConfig.blockedDomains,
    };
  }

  // â”€â”€ Scrape de uma Ãºnica URL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  async scrape(url: string, options: ScrapeOptions = {}): Promise<ScrapeResult> {
    // ValidaÃ§Ã£o anti-SSRF antes de qualquer requisiÃ§Ã£o
    const validUrl = await validateUrl(url, {
      allowedDomains: this.config.allowedDomains,
      blockedDomains: this.config.blockedDomains,
    });

    const mergedOptions: ScrapeOptions = {
      timeout: this.config.timeout,
      ...options,
    };

    // â”€â”€ Tier forÃ§ado: pula a cascata automÃ¡tica â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const forced = options.forceTier ?? this.config.forceTier;

    if (forced === "browser") {
      this.log("ğŸŒ Tier 3 (Playwright) forÃ§ado");
      return this.tier3.scrape(validUrl, mergedOptions);
    }

    if (forced === "stealth") {
      this.log("ğŸ¥· Tier 2 (Stealth HTTP) forÃ§ado");
      return this.tier2.scrape(validUrl, mergedOptions);
    }

    if (forced === "http") {
      this.log("ğŸ”— Tier 1 (HTTP) forÃ§ado");
      return this.tier1.scrape(validUrl, mergedOptions);
    }

    // â”€â”€ Modo automÃ¡tico: Tier 1 â†’ Tier 2 â†’ Tier 3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    // â”€â”€ Tier 1: HTTP puro (fetch nativo, sem overhead de TLS) â”€â”€â”€â”€â”€â”€â”€â”€â”€
    let tier1Error: string | null = null;
    try {
      const result = await this.tier1.scrape(validUrl, mergedOptions);
      const content = result.markdown ?? result.text ?? "";

      // Menos de 200 chars sem dados SSR = pÃ¡gina quase certamente vazia
      // (SPA sem SSR, Cloudflare challenge, bloqueio silencioso, etc.)
      if (content.length < 200 && !result.ssrData) {
        tier1Error = "ConteÃºdo insuficiente apÃ³s HTTP â€” provavelmente SPA ou bloqueio silencioso";
        this.log(`âš   Tier 1: ${tier1Error}`);
      } else {
        this.log(`âœ“ Tier 1 (HTTP) â€” ${result.durationMs}ms`);
        return result;
      }
    } catch (err) {
      tier1Error = err instanceof Error ? err.message : String(err);
      this.log(`âš   Tier 1 falhou: ${tier1Error}`);
    }

    // â”€â”€ Tier 2: HTTP Stealth (got-scraping, TLS fingerprint) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    let tier2Error: string | null = null;
    this.log("ğŸ¥· Ativando fallback â†’ Tier 2 (Stealth HTTP)...");
    try {
      const result = await this.tier2.scrape(validUrl, mergedOptions);
      const content = result.markdown ?? result.text ?? "";

      // Mesmo com TLS spoofing pode ser SPA que precisa de browser
      if (content.length < 200 && !result.ssrData) {
        tier2Error = "ConteÃºdo insuficiente apÃ³s Stealth â€” SPA que precisa de browser";
        this.log(`âš   Tier 2: ${tier2Error}`);
      } else {
        this.log(`âœ“ Tier 2 (Stealth) â€” ${result.durationMs}ms`);
        return result;
      }
    } catch (err) {
      tier2Error = err instanceof Error ? err.message : String(err);
      this.log(`âš   Tier 2 (Stealth) falhou: ${tier2Error}`);
    }

    // â”€â”€ Tier 3: Playwright Chromium + stealth (fallback final) â”€â”€â”€â”€â”€â”€â”€â”€
    this.log("ğŸŒ Ativando fallback final â†’ Tier 3 (Playwright)...");
    try {
      const result = await this.tier3.scrape(validUrl, mergedOptions);
      this.log(`âœ“ Tier 3 (Playwright) â€” ${result.durationMs}ms`);
      return result;
    } catch (err) {
      const tier3Error = err instanceof Error ? err.message : String(err);
      this.log(`âœ— Tier 3 (Playwright) falhou: ${tier3Error}`);

      // Todos os tiers falharam â€” retorna resultado com erro consolidado
      return {
        url: validUrl,
        statusCode: 0,
        title: "",
        tier: "browser",
        durationMs: 0,
        error: [
          "Todos os tiers falharam:",
          `  Tier 1 (HTTP):    ${tier1Error ?? "nÃ£o tentado"}`,
          `  Tier 2 (Stealth): ${tier2Error ?? "nÃ£o tentado"}`,
          `  Tier 3 (Browser): ${tier3Error}`,
        ].join("\n"),
      };
    }
  }

  // â”€â”€ Map: descobrir URLs de um site â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  /**
   * Mapeia links de uma pÃ¡gina (URL + texto do Ã¢ncora).
   * Reutiliza a cascata de tiers (HTTP â†’ Stealth â†’ Browser).
   *
   * @param url - URL base para extrair links
   * @param options - Filtros e limites
   */
  async map(url: string, options: MapOptions = {}): Promise<MapResult> {
    const startTime = Date.now();
    const limit = options.limit ?? 500;
    const includeSubdomains = options.includeSubdomains ?? true;
    const ignoreQueryParameters = options.ignoreQueryParameters ?? true;
    const searchTerm = options.search?.toLowerCase().trim();

    let scrapeResult: ScrapeResult;

    try {
      scrapeResult = await this.scrape(url, {
        getRawHtml: true,
        forceTier: options.forceTier,
      });
    } catch (err) {
      const errorMsg = err instanceof Error ? err.message : String(err);
      return {
        url,
        links: [],
        tier: "http",
        durationMs: Date.now() - startTime,
        error: `Falha ao carregar a pÃ¡gina: ${errorMsg}`,
      };
    }

    if (scrapeResult.error) {
      return {
        url: scrapeResult.url,
        links: [],
        tier: scrapeResult.tier,
        durationMs: scrapeResult.durationMs,
        error: scrapeResult.error,
      };
    }

    const rawHtml = scrapeResult.rawHtml ?? scrapeResult.html ?? "";
    if (!rawHtml) {
      return {
        url: scrapeResult.url,
        links: [],
        tier: scrapeResult.tier,
        durationMs: scrapeResult.durationMs,
        error: "HTML nÃ£o disponÃ­vel para extraÃ§Ã£o de links",
      };
    }

    const baseUrl = scrapeResult.url;
    const baseHostname = new URL(baseUrl).hostname;
    const baseDomain = baseHostname.replace(/^www\./, "");

    let links = extractLinksWithMetadata(rawHtml, baseUrl);

    // Filtrar por mesmo domÃ­nio
    links = links.filter((link) => {
      try {
        const linkHost = new URL(link.url).hostname.replace(/^www\./, "");
        if (includeSubdomains) {
          return linkHost === baseDomain || linkHost.endsWith(`.${baseDomain}`);
        }
        return linkHost === baseDomain;
      } catch {
        return false;
      }
    });

    // Normalizar URL (remover query string) e deduplicar
    const normalizeUrl = (href: string): string => {
      if (!ignoreQueryParameters) return href;
      try {
        const u = new URL(href);
        u.search = "";
        return u.href;
      } catch {
        return href;
      }
    };

    const seen = new Set<string>();
    const deduped: MapLink[] = [];
    for (const link of links) {
      const key = ignoreQueryParameters ? normalizeUrl(link.url) : link.url;
      if (seen.has(key)) continue;
      seen.add(key);
      deduped.push({
        url: link.url,
        title: link.title || undefined,
      });
    }
    links = deduped;

    // Filtrar e ordenar por search (relevÃ¢ncia simples)
    if (searchTerm) {
      const escaped = searchTerm.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
      const regex = new RegExp(escaped, "gi");
      const scored = links
        .map((link) => {
          const urlLower = link.url.toLowerCase();
          const titleLower = (link.title ?? "").toLowerCase();
          const urlMatches = (urlLower.match(regex) ?? []).length;
          const titleMatches = (titleLower.match(regex) ?? []).length;
          const score = urlMatches * 2 + titleMatches * 3; // title tem mais peso
          return { link, score };
        })
        .filter(({ score }) => score > 0)
        .sort((a, b) => b.score - a.score)
        .map(({ link }) => link);
      links = scored;
    }

    const result: MapResult = {
      url: baseUrl,
      links: links.slice(0, limit),
      tier: scrapeResult.tier,
      durationMs: Date.now() - startTime,
    };

    this.log(`âœ“ Map: ${result.links.length} links (${result.tier})`);
    return result;
  }

  // â”€â”€ Scrape em lote com concorrÃªncia controlada â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  /**
   * Scrapia mÃºltiplas URLs em paralelo com concorrÃªncia limitada.
   * Erros em URLs individuais nÃ£o derrubam o lote inteiro.
   *
   * @param urls - Lista de URLs a scrapeiar
   * @param options - OpÃ§Ãµes aplicadas a todas as URLs
   * @param concurrency - MÃ¡ximo de scrapes simultÃ¢neos. Default: 3
   */
  async scrapeMany(
    urls: string[],
    options: ScrapeOptions = {},
    concurrency = 3,
  ): Promise<ScrapeResult[]> {
    const results: ScrapeResult[] = [];
    const queue = [...urls];

    while (queue.length > 0) {
      const batch = queue.splice(0, concurrency);
      const settled = await Promise.allSettled(
        batch.map((u) => this.scrape(u, options)),
      );

      for (const outcome of settled) {
        if (outcome.status === "fulfilled") {
          results.push(outcome.value);
        } else {
          results.push({
            url: "unknown",
            statusCode: 0,
            title: "",
            tier: "http",
            durationMs: 0,
            error:
              outcome.reason instanceof Error
                ? outcome.reason.message
                : String(outcome.reason),
          });
        }
      }
    }

    return results;
  }

  // â”€â”€ Encerrar recursos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  /**
   * Fecha o browser Playwright (Tier 3).
   * Sempre chamar ao terminar para evitar processos Chromium Ã³rfÃ£os.
   */
  async close(): Promise<void> {
    await this.tier3.close();
  }

  // â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private log(msg: string): void {
    if (this.config.verbose) {
      console.log(`[Scraper] ${msg}`);
    }
  }
}

// Re-exporta tipos para conveniÃªncia
export type {
  ScrapeOptions,
  ScrapeResult,
  ScrapeTier,
  ContentFormat,
  SSRData,
  InterceptedAPI,
  ScraperConfig,
  TierRawResult,
  MapLink,
  MapOptions,
  MapResult,
} from "./types.js";
